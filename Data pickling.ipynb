{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from six.moves import cPickle as pickle\n",
    "import random\n",
    "from skimage import io, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/code/train_folder7/benign.pickle already present - Skipping pickling.\n",
      "/home/ubuntu/code/train_folder7/malignant.pickle already present - Skipping pickling.\n",
      "/home/ubuntu/code/test_folder7/benign.pickle already present - Skipping pickling.\n",
      "/home/ubuntu/code/test_folder7/malignant.pickle already present - Skipping pickling.\n"
     ]
    }
   ],
   "source": [
    "# pickle the benign, malignant subfolder in train_folders and test_folders.\n",
    "# change the 'train_folders' and 'test_folders' to locate your processed image data.\n",
    "width = 40\n",
    "height = 40\n",
    "pixel_depth = 255.0\n",
    "\n",
    "train_folders = ['/home/ubuntu/code/train_folder7/benign', '/home/ubuntu/code/train_folder7/malignant']\n",
    "test_folders = ['/home/ubuntu/code/test_folder7/benign', '/home/ubuntu/code/test_folder7/malignant']\n",
    "\n",
    "def load_file(folder):\n",
    "    image_files = os.listdir(folder)\n",
    "    dataset = np.ndarray(shape=(len(image_files), height, width),\n",
    "                         dtype=np.float32)\n",
    "    image_index = 0\n",
    "    print(folder)\n",
    "    for image in os.listdir(folder):\n",
    "        image_file = os.path.join(folder, image)\n",
    "        try:\n",
    "            image_data = (color.rgb2gray(ndimage.imread(image_file).astype(float)) - \n",
    "                        pixel_depth / 2) / pixel_depth\n",
    "            if image_data.shape != (height, width):\n",
    "                raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "            dataset[image_index, :, :] = image_data\n",
    "            image_index += 1\n",
    "        except IOError as e:\n",
    "            print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    \n",
    "    num_images = image_index\n",
    "    dataset = dataset[0:num_images, :, :]\n",
    "    \n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('Mean:', np.mean(dataset))\n",
    "    print('Standard deviation:', np.std(dataset))\n",
    "    return dataset\n",
    "        \n",
    "def maybe_pickle(data_folders, force=False):\n",
    "    dataset_names = []\n",
    "    for folder in data_folders:\n",
    "        set_filename = folder + '.pickle'\n",
    "        dataset_names.append(set_filename)\n",
    "        if os.path.exists(set_filename) and not force:\n",
    "            print('%s already present - Skipping pickling.' % set_filename)\n",
    "        else:\n",
    "            print('Pickling %s.' % set_filename)\n",
    "            dataset = load_file(folder, min_num_images_per_class)\n",
    "            try:\n",
    "                with open(set_filename, 'wb') as f:\n",
    "                    pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "            except Exception as e:\n",
    "                print('Unable to save data to', set_filename, ':', e)\n",
    "  \n",
    "    return dataset_names\n",
    "\n",
    "train_datasets = maybe_pickle(train_folders)\n",
    "test_datasets = maybe_pickle(test_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of images in ', '/home/ubuntu/code/train_folder7/benign', ' : ', 10080)\n",
      "('Number of images in ', '/home/ubuntu/code/train_folder7/malignant', ' : ', 10080)\n",
      "('Number of images in ', '/home/ubuntu/code/test_folder7/benign', ' : ', 1440)\n",
      "('Number of images in ', '/home/ubuntu/code/test_folder7/malignant', ' : ', 1440)\n"
     ]
    }
   ],
   "source": [
    "# check the number of dataset in each subfolder\n",
    "def disp_number_images(data_folders):\n",
    "    for folder in data_folders:\n",
    "        pickle_filename = ''.join(folder) + '.pickle'\n",
    "        try:\n",
    "            with open(pickle_filename, 'rb') as f:\n",
    "                dataset = pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print('Unable to read data from', pickle_filename, ':', e)\n",
    "            return\n",
    "        print('Number of images in ', folder, ' : ', len(dataset))\n",
    "    \n",
    "disp_number_images(train_folders)\n",
    "disp_number_images(test_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '/home/ubuntu/code/train_folder7/benign.pickle')\n",
      "(1, '/home/ubuntu/code/train_folder7/malignant.pickle')\n",
      "(0, '/home/ubuntu/code/test_folder7/benign.pickle')\n",
      "(1, '/home/ubuntu/code/test_folder7/malignant.pickle')\n",
      "('Training:', (17280, 40, 40), (17280,))\n",
      "('Validation:', (2880, 40, 40), (2880,))\n",
      "('Testing:', (2880, 40, 40), (2880,))\n"
     ]
    }
   ],
   "source": [
    "# generate three 'data/label' pairs: train_dataset/train_labels, valid_dataset/valid_labels, test_dataset/test_labels\n",
    "# change the train_size, valid_size, and test_size based on the results in the above cell. \n",
    "# test_size = (num of images in test/benign) + (num of images in test/malignant)\n",
    "# valid_size = test_size\n",
    "# train_size = (num of images in train/benign) + (num of images in tain/malignant) - valid_size\n",
    "\n",
    "train_size = 17280\n",
    "valid_size = 2880\n",
    "test_size = 2880\n",
    "\n",
    "def make_arrays(nb_rows, height, width):\n",
    "    if nb_rows:\n",
    "        dataset = np.ndarray((nb_rows, height, width), dtype=np.float32)\n",
    "        labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "    else:\n",
    "        dataset, labels = None, None\n",
    "    return dataset, labels\n",
    "\n",
    "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
    "    num_classes = len(pickle_files)\n",
    "    valid_dataset, valid_labels = make_arrays(valid_size, height, width)\n",
    "    train_dataset, train_labels = make_arrays(train_size, height, width)\n",
    "    vsize_per_class = valid_size // num_classes\n",
    "    tsize_per_class = train_size // num_classes\n",
    "\n",
    "    start_v, start_t = 0, 0\n",
    "    end_v, end_t = vsize_per_class, tsize_per_class\n",
    "    end_l = vsize_per_class + tsize_per_class\n",
    "    for label, pickle_file in enumerate(pickle_files): \n",
    "        print(label, pickle_file)\n",
    "        try:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                class_set = pickle.load(f)\n",
    "                np.random.shuffle(class_set)\n",
    "            if valid_dataset is not None:\n",
    "                # None means it's a test set\n",
    "                valid_class = class_set[:vsize_per_class, :, :]\n",
    "                valid_dataset[start_v:end_v, :, :] = valid_class\n",
    "                valid_labels[start_v:end_v] = label\n",
    "                start_v += vsize_per_class\n",
    "                end_v += vsize_per_class\n",
    "\n",
    "            train_class = class_set[vsize_per_class:end_l, :, :]\n",
    "            train_dataset[start_t:end_t, :, :] = train_class\n",
    "            train_labels[start_t:end_t] = label\n",
    "            start_t += tsize_per_class\n",
    "            end_t += tsize_per_class\n",
    "        except Exception as e:\n",
    "            print('Unable to process data from', pickle_file, ':', e)\n",
    "            raise\n",
    "\n",
    "    return valid_dataset, valid_labels, train_dataset, train_labels\n",
    "\n",
    "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(\n",
    "  train_datasets, train_size, valid_size)\n",
    "_, _, test_dataset, test_labels = merge_datasets(test_datasets, test_size)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation,:,:]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the pickle file with three 'data/label' pairs\n",
    "pickle_file = 'breast.pickle'\n",
    "\n",
    "try:\n",
    "    f = open(pickle_file, 'wb')\n",
    "    save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
